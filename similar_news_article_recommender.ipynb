{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97d5ae6d-bcb5-4cea-a756-99f31253bd3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"tokyo-country-452614-f7\"\n",
    "\n",
    "!gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "557bc5b7-da32-4739-9232-658c16cf9e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting apache-beam\n",
      "  Downloading apache_beam-2.63.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting crcmod<2.0,>=1.7 (from apache-beam)\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting orjson<4,>=3.9.7 (from apache-beam)\n",
      "  Downloading orjson-3.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam)\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cloudpickle~=2.2.1 (from apache-beam)\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting fastavro<2,>=0.23.6 (from apache-beam)\n",
      "  Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting fasteners<1.0,>=0.3 (from apache-beam)\n",
      "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 (from apache-beam)\n",
      "  Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam)\n",
      "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: httplib2<0.23.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (0.22.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (4.23.0)\n",
      "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam)\n",
      "  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: numpy<2.3.0,>=1.14.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (1.26.4)\n",
      "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam)\n",
      "  Downloading objsize-0.7.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging>=22.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (24.2)\n",
      "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam)\n",
      "  Downloading pymongo-4.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (1.26.0)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (3.20.3)\n",
      "Collecting pydot<2,>=1.2.0 (from apache-beam)\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (2025.1)\n",
      "Collecting redis<6,>=5.0.0 (from apache-beam)\n",
      "  Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting regex>=2020.6.8 (from apache-beam)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (2.32.3)\n",
      "Collecting sortedcontainers>=2.4.0 (from apache-beam)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (4.12.2)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (0.23.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=3.12 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (6.0.2)\n",
      "Requirement already satisfied: pyarrow<17.0.0,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix<1 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (0.6)\n",
      "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam) (1.17.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<0.23.0,>=0.8->apache-beam) (3.2.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (0.22.3)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in /opt/conda/lib/python3.10/site-packages (from redis<6,>=5.0.0->apache-beam) (5.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam) (2024.12.14)\n",
      "Downloading apache_beam-2.63.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
      "Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m129.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
      "Downloading objsize-0.7.1-py3-none-any.whl (11 kB)\n",
      "Downloading orjson-3.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Downloading pymongo-4.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading redis-5.2.1-py3-none-any.whl (261 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Building wheels for collected packages: crcmod, dill, hdfs, docopt\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=23137 sha256=e13d4f101ede47f4af571d286d2b945bddff028bd88557d296ece7a5d65d110c\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78604 sha256=5e5f1ee03b61bc6dcda22a7e8620543818eabf74b6f4ce88c1f7e3f917555e34\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
      "  Building wheel for hdfs (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34383 sha256=79da48f78679ecca3aad39a4d0200fdce7b6dab283e6c8e28c141e9e44e48520\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13749 sha256=9e576b0bc47653c47ff2bcedab5897b34920b5b867a08041deccfe8404a5f1a3\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "Successfully built crcmod dill hdfs docopt\n",
      "Installing collected packages: sortedcontainers, docopt, crcmod, regex, redis, pydot, orjson, objsize, jsonpickle, grpcio, fasteners, fastavro, dnspython, dill, cloudpickle, pymongo, hdfs, apache-beam\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.70.0\n",
      "    Uninstalling grpcio-1.70.0:\n",
      "      Successfully uninstalled grpcio-1.70.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~rpc'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 3.1.1\n",
      "    Uninstalling cloudpickle-3.1.1:\n",
      "      Successfully uninstalled cloudpickle-3.1.1\n",
      "Successfully installed apache-beam-2.63.0 cloudpickle-2.2.1 crcmod-1.7 dill-0.3.1.1 dnspython-2.7.0 docopt-0.6.2 fastavro-1.10.0 fasteners-0.19 grpcio-1.65.5 hdfs-2.7.3 jsonpickle-3.4.2 objsize-0.7.1 orjson-3.10.15 pydot-1.4.2 pymongo-4.11.3 redis-5.2.1 regex-2024.11.6 sortedcontainers-2.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install apache-beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb2393f3-e0a2-4fa5-9d94-2f0bf55a8dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: apache-beam[gcp] in /opt/conda/lib/python3.10/site-packages (2.63.0)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (1.7)\n",
      "Requirement already satisfied: orjson<4,>=3.9.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (3.10.15)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (0.3.1.1)\n",
      "Requirement already satisfied: cloudpickle~=2.2.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (2.2.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (1.10.0)\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (0.19)\n",
      "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (1.65.5)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (2.7.3)\n",
      "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (0.22.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (4.23.0)\n",
      "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (3.4.2)\n",
      "Requirement already satisfied: numpy<2.3.0,>=1.14.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (1.26.4)\n",
      "Requirement already satisfied: objsize<0.8.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (0.7.1)\n",
      "Requirement already satisfied: packaging>=22.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (24.2)\n",
      "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (4.11.3)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (1.26.0)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (3.20.3)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (2025.1)\n",
      "Requirement already satisfied: redis<6,>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (5.2.1)\n",
      "Requirement already satisfied: regex>=2020.6.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (2024.11.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (2.32.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (4.12.2)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (0.23.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=3.12 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (6.0.2)\n",
      "Requirement already satisfied: pyarrow<17.0.0,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix<1 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (0.6)\n",
      "Requirement already satisfied: cachetools<6,>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (5.5.1)\n",
      "Collecting google-api-core<3,>=2.0.0 (from apache-beam[gcp])\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-apitools<0.5.32,>=0.5.31 (from apache-beam[gcp])\n",
      "  Downloading google-apitools-0.5.31.tar.gz (173 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (2.38.0)\n",
      "Requirement already satisfied: google-auth-httplib2<0.3.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (0.2.0)\n",
      "Collecting google-cloud-datastore<3,>=2.0.0 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_datastore-2.20.2-py2.py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-cloud-pubsub<3,>=2.1.0 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_pubsub-2.29.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting google-cloud-pubsublite<2,>=1.2.0 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_pubsublite-1.12.0-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting google-cloud-storage<3,>=2.18.2 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: google-cloud-bigquery<4,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage<3,>=2.6.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (2.28.0)\n",
      "Requirement already satisfied: google-cloud-core<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (2.4.1)\n",
      "Collecting google-cloud-bigtable<3,>=2.19.0 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_bigtable-2.30.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting google-cloud-spanner<4,>=3.0.0 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_spanner-3.53.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting google-cloud-dlp<4,>=3.0.0 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_dlp-3.29.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: google-cloud-language<3,>=2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (2.16.0)\n",
      "Collecting google-cloud-videointelligence<3,>=2.0 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_videointelligence-2.16.1-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting google-cloud-vision<4,>=2 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_vision-3.10.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting google-cloud-recommendations-ai<0.11.0,>=0.1.0 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_recommendations_ai-0.10.17-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: google-cloud-aiplatform<2.0,>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (1.79.0)\n",
      "Requirement already satisfied: keyrings.google-artifactregistry-auth in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (1.1.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3,>=2.0.0->apache-beam[gcp]) (1.67.0rc1)\n",
      "Requirement already satisfied: oauth2client>=1.4.12 in /opt/conda/lib/python3.10/site-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]) (4.1.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]) (1.17.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]) (4.9)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]) (1.14.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]) (2.0.7)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]) (2.10.6)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]) (0.16)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4,>=2.0.0->apache-beam[gcp]) (2.7.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]) (0.14.0)\n",
      "Requirement already satisfied: google-crc32c<2.0.0dev,>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]) (1.6.0)\n",
      "Requirement already satisfied: grpcio-status>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (1.49.0rc1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.27.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.27.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (1.27.0)\n",
      "Requirement already satisfied: overrides<8.0.0,>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]) (7.7.0)\n",
      "Requirement already satisfied: sqlparse>=0.4.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]) (0.5.3)\n",
      "Collecting grpc-interceptor>=0.15.4 (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp])\n",
      "  Downloading grpc_interceptor-0.15.4-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]) (0.6.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<0.23.0,>=0.8->apache-beam[gcp]) (3.2.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]) (0.22.3)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from pymongo<5.0.0,>=3.8.0->apache-beam[gcp]) (2.7.0)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in /opt/conda/lib/python3.10/site-packages (from redis<6,>=5.0.0->apache-beam[gcp]) (5.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]) (2024.12.14)\n",
      "Requirement already satisfied: keyring in /opt/conda/lib/python3.10/site-packages (from keyrings.google-artifactregistry-auth->apache-beam[gcp]) (25.6.0)\n",
      "Requirement already satisfied: pluggy in /opt/conda/lib/python3.10/site-packages (from keyrings.google-artifactregistry-auth->apache-beam[gcp]) (1.5.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from oauth2client>=1.4.12->google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]) (0.6.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (8.4.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (0.48b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]) (2.27.2)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (3.3.3)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (0.8.0)\n",
      "Requirement already satisfied: jaraco.classes in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (3.4.0)\n",
      "Requirement already satisfied: jaraco.functools in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (4.1.0)\n",
      "Requirement already satisfied: jaraco.context in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (6.0.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (1.17.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (3.21.0)\n",
      "Requirement already satisfied: cryptography>=2.0 in /opt/conda/lib/python3.10/site-packages (from SecretStorage>=3.2->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (44.0.0)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from jaraco.classes->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (10.6.0)\n",
      "Requirement already satisfied: backports.tarfile in /opt/conda/lib/python3.10/site-packages (from jaraco.context->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (2.22)\n",
      "Downloading google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "Downloading google_cloud_bigtable-2.30.0-py3-none-any.whl (484 kB)\n",
      "Downloading google_cloud_datastore-2.20.2-py2.py3-none-any.whl (197 kB)\n",
      "Downloading google_cloud_dlp-3.29.0-py3-none-any.whl (213 kB)\n",
      "Downloading google_cloud_pubsub-2.29.0-py2.py3-none-any.whl (317 kB)\n",
      "Downloading google_cloud_pubsublite-1.12.0-py2.py3-none-any.whl (322 kB)\n",
      "Downloading google_cloud_recommendations_ai-0.10.17-py3-none-any.whl (211 kB)\n",
      "Downloading google_cloud_spanner-3.53.0-py2.py3-none-any.whl (483 kB)\n",
      "Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n",
      "Downloading google_cloud_videointelligence-2.16.1-py3-none-any.whl (274 kB)\n",
      "Downloading google_cloud_vision-3.10.1-py3-none-any.whl (526 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.1/526.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpc_interceptor-0.15.4-py3-none-any.whl (20 kB)\n",
      "Building wheels for collected packages: google-apitools\n",
      "  Building wheel for google-apitools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131078 sha256=6fe2d44d38dce7d1727a0b8c17bda4ea84bbe9637584921c2654338853a6e60f\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/04/b7/e0/9712f8c23a5da3d9d16fb88216b897bf60e85b12f5470f26ee\n",
      "Successfully built google-apitools\n",
      "Installing collected packages: grpc-interceptor, google-apitools, google-api-core, google-cloud-vision, google-cloud-videointelligence, google-cloud-storage, google-cloud-spanner, google-cloud-recommendations-ai, google-cloud-pubsub, google-cloud-dlp, google-cloud-datastore, google-cloud-bigtable, google-cloud-pubsublite\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 1.34.1\n",
      "    Uninstalling google-api-core-1.34.1:\n",
      "      Successfully uninstalled google-api-core-1.34.1\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/~pi_core'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.14.0\n",
      "    Uninstalling google-cloud-storage-2.14.0:\n",
      "      Successfully uninstalled google-cloud-storage-2.14.0\n",
      "  Attempting uninstall: google-cloud-datastore\n",
      "    Found existing installation: google-cloud-datastore 1.15.5\n",
      "    Uninstalling google-cloud-datastore-1.15.5:\n",
      "      Successfully uninstalled google-cloud-datastore-1.15.5\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/cloud/~atastore'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/cloud/~atastore_v1'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.24.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-api-core-2.24.2 google-apitools-0.5.31 google-cloud-bigtable-2.30.0 google-cloud-datastore-2.20.2 google-cloud-dlp-3.29.0 google-cloud-pubsub-2.29.0 google-cloud-pubsublite-1.12.0 google-cloud-recommendations-ai-0.10.17 google-cloud-spanner-3.53.0 google-cloud-storage-2.19.0 google-cloud-videointelligence-2.16.1 google-cloud-vision-3.10.1 grpc-interceptor-0.15.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install apache-beam[gcp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47b9bb1a-1799-4e11-8bd5-56818bb6fca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "from typing import Type\n",
    "from typing import Dict\n",
    "import apache_beam as beam\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform_v1\n",
    "from apache_beam.pipeline import PipelineOptions\n",
    "from google.protobuf import struct_pb2\n",
    "\n",
    "REGION = \"us-central1\"\n",
    "BUCKET_NAME = \"gs://my-first-bucket-invpc\" #add the bucket link here\n",
    "DEPLOYED_MODEL_ID = \"\" #add the deployed model id here later.\n",
    "\n",
    "ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "PARENT = \"projects/{}/locations/{}\".format(PROJECT_ID,REGION)\n",
    "DIMENSIONS = 512\n",
    "DISPLAY_NAME = \"similar_article_index\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f37588-00e0-4422-8af9-f18316ff7384",
   "metadata": {},
   "source": [
    "Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0b7e7a8-ba0a-41b1-a3d3-acdc4b5383bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(data:str) -> Dict:\n",
    "    data = json.loads(data)\n",
    "    data[\"text\"] = data[\"headline\"]+\"\"+data[\"short_description\"]\n",
    "    filtered_char = [ \"\\t\", \"\\0\", \"\\a\", \"\\b\", \"\\f\", \"\\r\", \"\\x0b\", \"\\x0c\", '\"', \"\\xa0\", \"\\n\", \"\\xad\", \"\\x99\", \"\\x94\", \"\\x93\", \"\\x80\", \"\\x7f\" ]\n",
    "    \n",
    "    for char in filtered_char:\n",
    "        data[\"text\"] = data[\"text\"].replace(char,\"\")\n",
    "        \n",
    "    data[\"text\"] = data[\"text\"].replace('\"\\\"',\"\")\n",
    "    data[\"text\"] = data[\"text\"].replace(\"'\",\"##\")\n",
    "    \n",
    "    return{\n",
    "        \"article_id\":data[\"link\"],\n",
    "        \"bytes_input\": data[\"text\"]\n",
    "    }\n",
    "    \n",
    "def build_pipeline(pipeline: beam.Pipeline):\n",
    "    #building apache beam pipeline\n",
    "    \n",
    "    articles_source_file = \"gs://my-first-bucket-invpc/News_Category_Dataset_v3.json\" #add the data file here\n",
    "    \n",
    "    steps = (pipeline\n",
    "            | \"Read article file\" >> beam.io.ReadFromText(articles_source_file,skip_header_lines=1)\n",
    "            | \"article text parser\" >> beam.Map(process)\n",
    "            | \"change char 1\" >> beam.Map(lambda x:str(x).replace(\"'\",'\"'))\n",
    "            | \"change char 2\" >> beam.Map(lambda x:str(x).replace(\"##\",\"'\"))\n",
    "            | \"write instances to jsonl\" >> beam.io.WriteToText(\n",
    "                file_path_prefix=\"gs://my-first-bucket-invpc/data/for-embedding\",file_name_suffix=\".jsonl\")\n",
    "            )\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a11e4d1-d2e3-471e-863c-eae3e8ce678a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:Bucket specified in temp_location has soft-delete policy enabled. To avoid being billed for unnecessary storage costs, turn off the soft delete feature on buckets that your Dataflow jobs use for temporary and staging storage. For more information, see https://cloud.google.com/storage/docs/use-soft-delete#remove-soft-delete-policy.\n",
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/home/jupyter/.local/share/jupyter/runtime/kernel-e3017579-c6ec-40ea-8f49-a108cd3fdd03.json']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    div.alert {\n",
       "      white-space: pre-line;\n",
       "    }\n",
       "  </style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css\" integrity=\"sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh\" crossorigin=\"anonymous\">\n",
       "            <div class=\"alert alert-info\">No cache_root detected. Defaulting to staging_location gs://my-first-bucket-invpc/temp for cache location.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:Bucket specified in temp_location has soft-delete policy enabled. To avoid being billed for unnecessary storage costs, turn off the soft delete feature on buckets that your Dataflow jobs use for temporary and staging storage. For more information, see https://cloud.google.com/storage/docs/use-soft-delete#remove-soft-delete-policy.\n",
      "WARNING:apache_beam.options.pipeline_options:Bucket specified in staging_location has soft-delete policy enabled. To avoid being billed for unnecessary storage costs, turn off the soft delete feature on buckets that your Dataflow jobs use for temporary and staging storage. For more information, see https://cloud.google.com/storage/docs/use-soft-delete#remove-soft-delete-policy.\n",
      "WARNING:apache_beam.options.pipeline_options:Unknown pipeline options received: -f,/home/jupyter/.local/share/jupyter/runtime/kernel-e3017579-c6ec-40ea-8f49-a108cd3fdd03.json. Ignore if flags are used for internal purposes.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding flag -f, single dash flags are not allowed.\n",
      "WARNING:apache_beam.options.pipeline_options:Unknown pipeline options received: -f,/home/jupyter/.local/share/jupyter/runtime/kernel-e3017579-c6ec-40ea-8f49-a108cd3fdd03.json. Ignore if flags are used for internal purposes.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding flag -f, single dash flags are not allowed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "options = PipelineOptions(\n",
    "    runner = \"DataflowRunner\",\n",
    "    project = PROJECT_ID,\n",
    "    temp_location = \"gs://my-first-bucket-invpc/temp\",\n",
    "    region = REGION)\n",
    "\n",
    "with beam.Pipeline(options=options) as pipeline:\n",
    "    build_pipeline(pipeline)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c85af89-0ec2-41ba-9635-cabb5a4ccfb3",
   "metadata": {},
   "source": [
    "Change Model Input/Output Signature for customized output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b26437bf-c425-4eca-8deb-454b6e2cfaf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.65.5)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.9.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.8/644.8 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (395 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, markdown, h5py, google-pasta, gast, astunparse, tensorboard, keras, tensorflow\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 h5py-3.13.0 keras-3.9.0 libclang-18.1.1 markdown-3.7 ml-dtypes-0.5.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.14.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 werkzeug-3.1.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "159acca3-24a6-4bee-bbfe-5bb1bb1b8550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting.....\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def model_change_signature(model_path:str) -> None:\n",
    "    model = tf.saved_model.load(model_path)\n",
    "    \n",
    "    def _get_serve_fn(model):\n",
    "        @tf.function\n",
    "        def serve_fn(bytes_input,article_id):\n",
    "            \n",
    "            vector = model(bytes_input)\n",
    "            return {\n",
    "                \"article_id\": article_id,\n",
    "                \"embedding_vector\":vector\n",
    "            }\n",
    "        return serve_fn\n",
    "    \n",
    "    signatures = {\n",
    "        \"serving_default\": _get_serve_fn(model).get_concrete_function(\n",
    "            tf.TensorSpec(shape=[None],dtype=tf.string),\n",
    "            tf.TensorSpec(shape=[None],dtype=tf.string)\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    tf.saved_model.save(model,os.path.join(model_path,'wrapped_model'),signatures=signatures)\n",
    "    \n",
    "print(\"starting.....\")\n",
    "model_change_signature(\"gs://my-first-bucket-invpc/encoder/\") #add bucket link here\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f89820f2-b0c2-46f6-8f33-eed23a83cff5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signature: serving_default, Inputs: ((), {'article_id': TensorSpec(shape=(None,), dtype=tf.string, name='article_id'), 'bytes_input': TensorSpec(shape=(None,), dtype=tf.string, name='bytes_input')}), Outputs: {'embedding_vector': TensorSpec(shape=(None, 512), dtype=tf.float32, name='embedding_vector'), 'article_id': TensorSpec(shape=(None,), dtype=tf.string, name='article_id')}\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "\n",
    "saved_model_path = \"gs://my-first-bucket-invpc/encoder/wrapped_model\"\n",
    "loaded_model = tf.saved_model.load(saved_model_path)\n",
    "\n",
    "# Print available signatures\n",
    "for signature_key, signature in loaded_model.signatures.items():\n",
    "    print(f\"Signature: {signature_key}, Inputs: {signature.structured_input_signature}, Outputs: {signature.structured_outputs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e72ff-cb80-498c-84f6-b90902f28901",
   "metadata": {},
   "source": [
    "upload embeding model to Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f07904d7-0691-4bf8-8eca-fe98930a1b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name = \"universal_encoder_model_02\",\n",
    "    artifact_uri = \"gs://my-first-bucket-invpc/encoder/wrapped_model\",\n",
    "    serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest\",\n",
    "    sync=False,) #add bucket link for model\n",
    "\n",
    "model.wait()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495583f0-a384-47d9-95ef-0194f0bae0a5",
   "metadata": {},
   "source": [
    "Running Embedding Model Batch Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e932bc64-b662-42d9-a907-c1b74f793b33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL ID IS:  1530974284166463488\n"
     ]
    }
   ],
   "source": [
    "#get model id\n",
    "\n",
    "MODEL_NAME = \"universal_encoder_model_02\"\n",
    "models = aiplatform.Model.list()\n",
    "\n",
    "DEPLOYED_MODEL_ID = next(( m.name.split(\"/\")[-1] for m in models if m.display_name == MODEL_NAME),None)\n",
    "\n",
    "if DEPLOYED_MODEL_ID:\n",
    "    print(\"MODEL ID IS: \",DEPLOYED_MODEL_ID)\n",
    "else:\n",
    "    print(\"No Model found with name \" + MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9720dbd6-0a10-43b0-8438-07da03d3764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_endpoint = REGION + \"-aiplatform.googleapis.com\"\n",
    "client_options = {\"api_endpoint\":api_endpoint}\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID,location=REGION)\n",
    "\n",
    "client = aiplatform.gapic.JobServiceClient(\n",
    "    client_options=client_options\n",
    ")\n",
    "#Add one liner to get deployed model id from model registry in vertx ai platform\n",
    "model = aiplatform.Model(DEPLOYED_MODEL_ID) \n",
    "batch_prediction_job = {\n",
    "    \"display_name\":\"predicting_embeddings\",\n",
    "    \"model\":model.resource_name,\n",
    "    \"input_config\": {\n",
    "        \"instances_format\":\"jsonl\",\n",
    "        \"gcs_source\":{\"uris\":[BUCKET_NAME+\"/data/for-embedding-00001-of-00002.jsonl\"]}, #add data link here from gcs\n",
    "    },\n",
    "    \"output_config\":{\n",
    "        \"predictions_format\":\"jsonl\",\n",
    "        \"gcs_destination\":{\"output_uri_prefix\":BUCKET_NAME+\"/embeddings/\"},\n",
    "    },\n",
    "    \"dedicated_resources\":{\n",
    "        \"machine_spec\":{\n",
    "            \"machine_type\":\"n1-standard-32\",\n",
    "        },\n",
    "        \"starting_replica_count\":2,\n",
    "        \"max_replica_count\":2,\n",
    "    },\n",
    "    \"manual_batch_tuning_parameters\":{\n",
    "        \"batch_size\":5\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "parent = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "\n",
    "job = client.create_batch_prediction_job(\n",
    "    parent=parent,batch_prediction_job=batch_prediction_job\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505f5547-5525-4f7e-a084-43c47e4a68d8",
   "metadata": {},
   "source": [
    "Pipeline to transform embedding data for Maching Engine Index input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73846d61-7d45-42ae-9d1c-fa6a97ac9095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(data):\n",
    "    \n",
    "    data = json.loads(data)\n",
    "    data = data[\"prediction\"]\n",
    "    return{\n",
    "        \"id\":data[\"article_id\"],\n",
    "        \"embedding\":data[\"embedding_vector\"]\n",
    "    }\n",
    "\n",
    "def build_pipeline(pipeline : beam.Pipeline):\n",
    "    \n",
    "    embedding_source = BUCKET_NAME + \"/embeddings/prediction-universal_encoder_model_02-2025_03_21T15_06_52_816Z\" #add prediction directory name here\n",
    "    embedding_source_json_file = os.path.join(\n",
    "        embedding_source,'prediction.results-*')\n",
    "    \n",
    "    steps = (pipeline\n",
    "             |beam.io.ReadFromText(embedding_source_json_file) \n",
    "             |\"data parser\" >> beam.Map(process)\n",
    "             |\"write instances to jsonl\" >> beam.io.WriteToText(\n",
    "                 file_path_prefix=BUCKET_NAME+\"/vector_embeddings/\",file_name_suffix=\".json\",num_shards=20,shard_name_template=\"-SSSSS-of-NNNNN\")\n",
    "            )\n",
    "    return\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c1e9f30-ed38-4f30-a41b-1d58c8793785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/home/jupyter/.local/share/jupyter/runtime/kernel-e3017579-c6ec-40ea-8f49-a108cd3fdd03.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding invalid overrides: {'location': 'us-central1'}\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/home/jupyter/.local/share/jupyter/runtime/kernel-e3017579-c6ec-40ea-8f49-a108cd3fdd03.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding invalid overrides: {'location': 'us-central1'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "options = PipelineOptions(\n",
    "    project = PROJECT_ID,\n",
    "    location=REGION,\n",
    "    temp_location=BUCKET_NAME+\"/temp\"\n",
    ")\n",
    "\n",
    "with beam.Pipeline(options=options) as pipeline:\n",
    "    build_pipeline(pipeline)\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68931f63-eeff-4baa-a1db-bcf4efecc86f",
   "metadata": {},
   "source": [
    "Create The Maching Engine Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b78bb6f-c947-4550-9682-084e4a40b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(brute_force=False,stream_update=True):\n",
    "    \n",
    "    index_client = aiplatform_v1.IndexServiceClient(client_options = dict(api_endpoint=ENDPOINT))\n",
    "    \n",
    "    if brute_force:\n",
    "        algorithmConfig = struct_pb2.Struct(fields={\n",
    "        \"bruteForceConfig\": struct_pb2.Value(struct_value = struct_pb2.Struct())})\n",
    "    else:\n",
    "        treeAhConfig = struct_pb2.Struct(fields={\n",
    "        \"leafNodeEmbeddingCount\": struct_pb2.Value(number_value=500),\n",
    "        \"leafNodesToSearchPercent\": struct_pb2.Value(number_value=10)\n",
    "        })\n",
    "        \n",
    "        algorithmConfig = struct_pb2.Struct(fields = {\n",
    "        \"treeAhConfig\":struct_pb2.Value(struct_value=treeAhConfig)})\n",
    "    \n",
    "    index_config = struct_pb2.Struct(fields = {\n",
    "        \"dimensions\" : struct_pb2.Value(number_value=DIMENSIONS),\n",
    "        \"approximateNeighborsCount\" : struct_pb2.Value(number_value=150),\n",
    "        \"distanceMeasureType\" : struct_pb2.Value(string_value=\"COSINE_DISTANCE\"),\n",
    "        \"algorithmConfig\" : struct_pb2.Value(struct_value=algorithmConfig)\n",
    "    })\n",
    "    \n",
    "    metadata = struct_pb2.Struct(fields={\n",
    "        \"config\":struct_pb2.Value(struct_value=index_config),\n",
    "        \"contentsDeltaUri\": struct_pb2.Value(string_value=BUCKET_NAME+\"/vector_embeddings/\"),\n",
    "    })\n",
    "    \n",
    "    if stream_update:\n",
    "        index = {\n",
    "            \"display_name\": DISPLAY_NAME,\n",
    "            \"description\": \"stream update\",\n",
    "            \"metadata\": struct_pb2.Value(struct_value=metadata),\n",
    "            \"index_update_method\": aiplatform_v1.Index.IndexUpdateMethod.STREAM_UPDATE,\n",
    "        }\n",
    "    else:\n",
    "        index = {\n",
    "            \"display_name\": DISPLAY_NAME,\n",
    "            \"description\": \"batch update\",\n",
    "            \"metadata\": struct_pb2.Value(struct_value=metadata),\n",
    "            \"index_update_method\": aiplatform_v1.Index.IndexUpdateMethod.BATCH_UPDATE,\n",
    "        }\n",
    "        \n",
    "        \n",
    "    create_index = index_client.create_index(parent=PARENT,index=index)\n",
    "    \n",
    "    while True:\n",
    "        if create_index.done():\n",
    "            break\n",
    "        logging.info(\"Poll the operation to create index....\")\n",
    "        time.sleep(60)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    create_index()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b06ee4-e1e7-4c82-9960-47730f99c72f",
   "metadata": {},
   "source": [
    "Create an Endpoint for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5717bde-51e2-4919-b7fa-c4f43a835708",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738666983022\n"
     ]
    }
   ],
   "source": [
    "#To get project number\n",
    "import subprocess\n",
    "\n",
    "command = f\"gcloud projects describe {PROJECT_ID} --format='value(projectNumber)'\"\n",
    "\n",
    "project_number = subprocess.check_output(command, shell=True).decode('utf-8').strip()\n",
    "\n",
    "print(project_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9199035-cc0d-4659-9a97-e4c9c52cb46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vpc_network = \"projects/{}/global/networks/my-first-vpc-network\".format(project_number)\n",
    "\n",
    "index_endpoint_client = aiplatform_v1.IndexEndpointServiceClient(\n",
    "        client_options=dict(api_endpoint=ENDPOINT)\n",
    ")\n",
    "\n",
    "index_endpoint = {\n",
    "    \"display_name\": DISPLAY_NAME + \"_endpoint\",\n",
    "    \"network\": vpc_network,\n",
    "}\n",
    "\n",
    "r = index_endpoint_client.create_index_endpoint(\n",
    "        parent=PARENT, index_endpoint=index_endpoint\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51185248-4ec4-4cd5-825e-fd9e2c5d6246",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/738666983022/locations/us-central1/indexEndpoints/5886622527391793152'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write a code to get index id through CLI command TO_DO\n",
    "r.result().name "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a4bc5a-dd01-4cb1-96e8-23a12e37fea7",
   "metadata": {},
   "source": [
    "Deploy the index to Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c5a1cfd-ac6c-4d98-802c-625c8162950a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "Poll the Operation to deploy index...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "index_id = \"584625725651288064\"#get the index id\n",
    "\n",
    "INDEX_ENDPOINT_NAME = r.result().name      #this will give index endpoint id\n",
    "DEPLOYED_INDEX_ID_NAME = DISPLAY_NAME + \"_deployed_index\"\n",
    "INDEX_ID = \"projects/{}/locations/{}/indexes/{}\".format(PROJECT_ID,REGION,index_id)     \n",
    "\n",
    "index = {\n",
    "    \"id\":DEPLOYED_INDEX_ID_NAME,\n",
    "    \"display_name\":DEPLOYED_INDEX_ID_NAME,\n",
    "    \"index\":INDEX_ID,\n",
    "}\n",
    "\n",
    "my_index_endpoint = index_endpoint_client.deploy_index(\n",
    "    index_endpoint = INDEX_ENDPOINT_NAME, deployed_index=index\n",
    ")\n",
    "\n",
    "while True:\n",
    "    if my_index_endpoint.done():\n",
    "        break\n",
    "    print(\"Poll the Operation to deploy index...\")\n",
    "    time.sleep(60)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a35093f-8214-4004-bcf7-da095d8e42bb",
   "metadata": {},
   "source": [
    "Query the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ee64b1c6-ac62-4fcd-bc40-c570116fee82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='https://www.huffingtonpost.com/entry/kentucky-voting-rights_us_5654806be4b0258edb32ebdc', distance=0.2433384656906128, sparse_distance=None, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None, sparse_embedding_values=None, sparse_embedding_dimensions=None),\n",
       "  MatchNeighbor(id='https://www.huffingtonpost.com/entry/felon-voting-rights-restoration_us_5655de80e4b079b28189da1e', distance=0.4399524927139282, sparse_distance=None, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None, sparse_embedding_values=None, sparse_embedding_dimensions=None),\n",
       "  MatchNeighbor(id='https://www.huffpost.com/entry/florida-felons-vote-unpaid-fines-fees_n_5e4e1e24c5b630e74c504927', distance=0.5182387232780457, sparse_distance=None, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None, sparse_embedding_values=None, sparse_embedding_dimensions=None),\n",
       "  MatchNeighbor(id='https://www.huffingtonpost.com/entry/rick-scott-felon-disenfranchisement_us_5ac50856e4b09ef3b242f45f', distance=0.5196278095245361, sparse_distance=None, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None, sparse_embedding_values=None, sparse_embedding_dimensions=None),\n",
       "  MatchNeighbor(id='https://www.huffpost.com/entry/florida-former-felons-vote-restored_n_5c332425e4b0bcb4c25da9b6', distance=0.5287047028541565, sparse_distance=None, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None, sparse_embedding_values=None, sparse_embedding_dimensions=None),\n",
       "  MatchNeighbor(id='https://www.huffingtonpost.com/entry/florida-felon-rights-restoration_us_5a748acee4b06ee97af222fd', distance=0.5326089859008789, sparse_distance=None, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None, sparse_embedding_values=None, sparse_embedding_dimensions=None),\n",
       "  MatchNeighbor(id='https://www.huffingtonpost.com/entry/republicans-felon-voting-rights_us_57277ec0e4b01a5ebde6275c', distance=0.5393484234809875, sparse_distance=None, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None, sparse_embedding_values=None, sparse_embedding_dimensions=None),\n",
       "  MatchNeighbor(id='https://www.huffingtonpost.com/entry/louisiana-felon-disenfranchisement-voting-rights_us_5afc9888e4b06a3fb50d46cc', distance=0.5410577058792114, sparse_distance=None, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None, sparse_embedding_values=None, sparse_embedding_dimensions=None),\n",
       "  MatchNeighbor(id='https://www.huffingtonpost.com/entry/felony-voting-laws-are-confusing-activists-would-ditch_us_5ac6371ce4b01190c1ed6e41', distance=0.5422375202178955, sparse_distance=None, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None, sparse_embedding_values=None, sparse_embedding_dimensions=None),\n",
       "  MatchNeighbor(id='https://www.huffingtonpost.com/entry/new-jersey-prisoners-to-vote_us_5a942b9be4b01f65f598c58e', distance=0.5457629561424255, sparse_distance=None, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None, sparse_embedding_values=None, sparse_embedding_dimensions=None)]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "INDEX_ENDPOINT = 'projects/738666983022/locations/us-central1/indexEndpoints/5886622527391793152'\n",
    "DEPLOYED_INDEX_ID = 'similar_article_index_deployed_index'\n",
    "candidates_embedding = [[0.0502016456, -0.099912588, -0.8578929521, -0.035492491, -0.0298160315, 0.0578172, -0.0591950715, 0.00769451866, 0.0521428809, -0.0768064186, -0.0360548832, 0.0511014275, 0.0607668199, -0.0167274252, 0.0278223436, -0.0733504072, -0.0553152338, 0.011630984, -0.0372170731, -0.03048319, -0.0561569594, 0.0393138938, 0.0769464225, 0.0459631607, 0.0162670016, 0.0580527596, -0.0380507633, 0.0437482595, -0.0216746423, -0.0175770447, -0.0174269807, 0.00592250936, 0.0195918, -0.0434573852, 0.0215063971, 0.0380142666, 0.0627181679, -0.00142126402, -0.0280464888, 0.081744507, 0.0385259166, -0.0194710102, 0.00883859769, 0.0104368478, 0.0115294335, 0.0502061024, 0.0377715714, -0.0470889807, 0.0254153796, -0.0689847767, -0.0717464909, -0.06491, 0.0126711708, 0.0112836855, -0.0541676097, -0.0356421433, -0.0164782982, -0.0610802695, 0.0423853733, 0.0488026142, -0.0289505068, -0.000677486591, -0.0476895459, 0.00380550791, -0.0596526153, -0.00640337588, -0.0220143981, 0.0359431, 0.0322990753, -0.0474538691, 0.054927133, -0.00737987272, 0.0140833808, 0.0443712324, -0.043933779, 0.0409256071, 0.00772624137, -0.0229224265, -0.0722916, 0.0597278886, -0.0442352816, 0.00616668351, 0.000982288155, 0.0568430573, -0.060338337, 0.0552312955, 0.00631992472, -0.0821219385, 0.0561952889, 0.0680704713, 0.0169057455, -0.0601352453, -0.00401292695, 0.0737325177, -0.0767178312, 0.0433958881, 0.0168477539, -0.0603372641, 0.0803615153, -0.0396288484, 0.00747376308, 0.0123901023, -0.0492022783, -0.0297769308, 0.0600016415, 0.0327744, -0.0383736119, 0.00626307772, 0.075845331, 0.0704802126, -0.019431429, 0.0147908265, 0.0115813557, 0.051621, 0.00542780757, 0.0571184829, 0.0614894032, -0.0470786393, 0.0623328239, -0.052912388, -0.0170839764, 0.00801151618, -0.039427653, 0.0572161525, 0.00167220051, 0.0406115353, 0.042143587, 0.0578572936, 0.00313223619, -0.0323182568, -0.0586032756, -0.0639747679, -0.00879042, -0.00917307194, 0.0182663631, 0.0175092723, -0.0254115406, 0.00019361559, -0.0317655206, -0.0563735217, 0.078452155, 0.0507345274, 0.0173529927, -0.0490901545, -0.0822084844, 0.081648849, 0.0261113588, -0.0563871451, -0.0518015586, -0.0348771252, -0.0398101844, -0.0139666991, 0.0184999667, -0.0375076868, 0.0602380857, -0.0249493979, 0.0734049156, -0.0512630902, 0.0289901346, 0.0765650347, -0.0669102296, -0.0722649768, -0.0313954577, 0.0154615585, -0.00943078, 0.0787919909, 0.0673941597, 0.0311770607, 0.0354374647, -0.0265306365, 0.0437518097, -0.0732665658, 0.0489297248, 0.0655555576, -0.0393787138, -0.0388070829, 0.00970042683, -0.0311868507, -0.0827492177, -0.0206832308, -0.0519809723, -0.00493504945, -0.0685245842, -0.0282617398, 0.0355950221, -0.00734898634, 0.0376003645, 0.0253161155, 0.0584747083, 0.0212987959, -0.0384559371, 0.082592912, 0.0311547089, 0.0624623373, -0.0814144462, 0.0395354666, -0.0231002867, 0.0421228856, -0.0316452384, 0.00487433653, 0.081918, 0.0544711351, -0.0105061373, -0.0656491295, 0.0633879, 0.0184279773, 0.0244700145, -0.0186490659, 0.0489147231, -0.0642368719, -0.0202094428, 0.0435244404, 0.0441161953, -0.0397966728, 0.00379270967, -0.0826089457, -0.0361774899, 0.0148726385, 0.062031, 0.0274232719, 0.0018814319, -0.0396838896, -0.00243198988, 0.0693733543, 0.0090195518, -0.0290311389, 0.0483087078, 0.0133154988, -0.00168000278, 0.0018319498, 0.0636196136, -0.00776374154, -0.0360434279, -0.0814935938, -0.0158276167, 0.076635845, 0.0709537119, 0.031912, 0.0192611646, -0.0020914129, -0.0175421238, -0.0556306057, 0.0562396981, -0.0131248496, -0.0311832521, -0.0389447063, 0.0081713954, -0.0650436059, -0.0728608742, 0.0381941162, 0.0728306696, -0.0333044268, -0.0498978645, 0.0464298204, 0.0603470914, 0.0245335829, -0.0466825403, 0.0367866494, 0.0354647525, 0.0224961024, 0.00907058641, 0.0262220241, 0.00287109287, -0.0202807207, -0.0611601658, -0.0140948519, -0.0241945963, 0.0169137083, 0.04755513, -0.072648935, -0.0248457938, 0.0134985298, 0.0326770581, -0.0753605962, 0.0431795977, 0.0070912689, 0.0538257435, -0.0551753193, 0.0802449882, -0.0442277, 0.0728385448, 0.0388735756, 0.0478703529, 0.0146021023, -0.0253923088, -0.0707472, -0.0463880636, 0.0812347755, -0.0660555139, 0.0275677182, 0.074266471, -0.00873696245, 0.0740572587, 0.0300100874, 0.0488660261, 0.00390042644, 0.0183884613, 0.0513804667, -0.0134160146, 0.0104410294, -0.0548431613, 0.00267668464, -0.0045957393, -0.0431737155, 0.0447403081, 0.0280321818, 0.0606655292, -0.044766, 0.00433506304, 0.0612494163, -0.0300246403, -0.0127954045, 0.0151460106, -0.0455670394, -0.0663784593, -0.0198004544, -0.0314645022, -0.0233538225, 0.0375389, 0.0419015922, 0.0114331888, -0.0567778945, -0.0205252562, 0.0640368462, 0.0304049719, 0.0418470241, 0.0718007684, 0.0249215048, 0.0485383123, 0.0256850589, 0.0161422547, -0.0715882853, -0.031735085, 0.00729028787, -0.0248725768, -0.0534334667, -0.00668986514, -0.0530478396, 0.0210357681, -0.0808970109, 0.0302360952, -0.0505049229, 0.000117966345, 0.0827040151, 0.01088777, -0.0417144224, -0.050915949, 0.0712650046, -0.0804398507, 0.013461112, -0.0690629, 0.0565128922, 0.0593511537, 0.054564774, 0.00770380441, 0.0287936367, -0.0799678564, 0.0595743619, -0.0295372885, 0.0749069, -0.0206449535, -0.0704574063, 0.0716846809, 0.0305647962, 0.0119375754, 0.0403936505, 0.0181931518, -0.0112507623, 0.0250820667, 0.0193080865, -0.00632366771, -0.0114755929, -0.062191505, 0.0511554033, 0.0264797751, -0.04922387, 0.067763187, 0.0448058881, -0.0122261066, -0.0782086775, -0.0218615942, 0.0469329022, -0.0729536265, 0.039681755, 0.0633885041, 0.0739140883, 0.000466615224, 0.00981137808, 0.0484512709, -0.0618514754, -0.0511878841, -0.0678248182, 0.0320391618, 0.0265220441, 0.0426274426, -0.0408450514, -0.0365734622, 0.0174115263, -0.0102628972, -0.0563230067, 0.029912306, 0.0348706208, -0.0441398956, 0.0484397821, -0.00193183741, -0.053231325, -0.0031785618, 0.0546823815, -0.0622022822, -0.0735706, 0.00255643437, -0.0140257142, -0.00473003043, 0.0171921067, -0.0228456222, 0.0364877656, 0.0294562951, 0.0120815663, -0.00332700461, -0.0322813839, -0.0772143155, -0.0101970853, -0.0344852097, -0.0511004366, -0.059917938, -0.0165633541, 0.00150151621, 0.0252316985, -0.0292765591, 0.0350353047, 0.0313969888, -0.037920475, -0.0100262454, 0.0595380031, 0.0212509129, 0.00227843691, 0.0123936273, -0.0618601, -0.0711660236, -0.0463614725, -0.0176716968, -0.041117616, 0.0501014404, 0.0740635619, 0.0316318125, 0.0319646634, -0.041036129, -0.0492766201, -0.0410203375, 0.0154050356, 0.00724651804, -0.00200869422, 0.0144809075, -0.00493975263, -0.0142480489, 0.00977388769, -0.0168318432, 0.0133904684, -0.0764209, 0.0188833009, 0.0278521795, 0.0216211285, 0.0184155144, 0.0710755959, -0.0332404673, 0.0428488292, 0.0556732714, -0.0496581122, -0.018820351, -0.0691318437, -0.0581589, 0.0407969728, -0.0256147366, 0.0421869494, -0.00859052, -0.0579928793, 0.0408137292, 0.0261646267, 0.000727738428, 0.0523216, -0.00628263596, 0.00592074869, 0.00385966455, -0.0548521131, -0.0591544136, 0.0423886739, 0.0418718494, -0.00265934318, -0.000706568069, -0.0224871896, -0.0124037191, -0.0377913229, -0.031713672, 0.00600458356, 0.0358984321, -0.0611761697, 0.0498134196, 0.0270567555, -0.0348888636, -0.0337959, -0.0809504, -0.0481201671, -0.0369402543, 0.0323536061, -0.0332562253, 0.0485725701, -0.0484549701, 0.0437381528, 0.00597401569, 0.0328890048, -0.0480710231, 0.0604506582]]\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(\"5886622527391793152\",location=\"us-central1\")\n",
    "\n",
    "response = my_index_endpoint.match(deployed_index_id=DEPLOYED_INDEX_ID,queries=candidates_embedding,num_neighbors=10)\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e980bda1-7c2d-49d7-aa36-d6b57fd78781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
