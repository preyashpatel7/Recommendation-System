{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "873392ac-b5c8-4b61-a54d-115f943c36be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.9.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (2.1.0)\n",
      "Collecting array_record>=0.5.0 (from tensorflow_datasets)\n",
      "  Downloading array_record-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (877 bytes)\n",
      "Requirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (0.1.9)\n",
      "Collecting etils>=1.6.0 (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets)\n",
      "  Downloading etils-1.12.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting immutabledict (from tensorflow_datasets)\n",
      "  Downloading immutabledict-4.2.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (1.26.4)\n",
      "Collecting promise (from tensorflow_datasets)\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.20 in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (3.20.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (5.9.3)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (15.0.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (2.32.3)\n",
      "Collecting simple_parsing (from tensorflow_datasets)\n",
      "  Downloading simple_parsing-0.1.7-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting tensorflow-metadata (from tensorflow_datasets)\n",
      "  Downloading tensorflow_metadata-1.16.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (2.5.0)\n",
      "Collecting toml (from tensorflow_datasets)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (4.67.1)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (1.17.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (2025.2.0)\n",
      "Collecting importlib_resources (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (4.12.2)\n",
      "Requirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (3.21.0)\n",
      "Collecting einops (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2024.12.14)\n",
      "Requirement already satisfied: attrs>=18.2.0 in /opt/conda/lib/python3.10/site-packages (from dm-tree->tensorflow_datasets) (25.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from promise->tensorflow_datasets) (1.17.0)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /opt/conda/lib/python3.10/site-packages (from simple_parsing->tensorflow_datasets) (0.16)\n",
      "Downloading tensorflow_datasets-4.9.8-py3-none-any.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading array_record-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading etils-1.12.2-py3-none-any.whl (167 kB)\n",
      "Downloading immutabledict-4.2.1-py3-none-any.whl (4.7 kB)\n",
      "Downloading simple_parsing-0.1.7-py3-none-any.whl (112 kB)\n",
      "Downloading tensorflow_metadata-1.16.1-py3-none-any.whl (28 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21548 sha256=84e090ee5c9cf37458e476737c00f16c3ca758d605ece963a8f101550992438c\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/54/4e/28/3ed0e1c8a752867445bab994d2340724928aa3ab059c57c8db\n",
      "Successfully built promise\n",
      "Installing collected packages: toml, tensorflow-metadata, simple_parsing, promise, importlib_resources, immutabledict, etils, einops, array_record, tensorflow_datasets\n",
      "Successfully installed array_record-0.7.1 einops-0.8.1 etils-1.12.2 immutabledict-4.2.1 importlib_resources-6.5.2 promise-2.3 simple_parsing-0.1.7 tensorflow-metadata-1.16.1 tensorflow_datasets-4.9.8 toml-0.10.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe716294-12ed-47c2-900d-a601d76259da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_recommenders\n",
      "  Downloading tensorflow_recommenders-0.7.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow_recommenders) (2.1.0)\n",
      "Requirement already satisfied: tensorflow>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_recommenders) (2.19.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.65.5)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (3.9.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow>=2.9.0->tensorflow_recommenders) (13.9.4)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.14.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.9.0->tensorflow_recommenders) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.9.0->tensorflow_recommenders) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.9.0->tensorflow_recommenders) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.9.0->tensorflow_recommenders) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow>=2.9.0->tensorflow_recommenders) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow>=2.9.0->tensorflow_recommenders) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow>=2.9.0->tensorflow_recommenders) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow>=2.9.0->tensorflow_recommenders) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow>=2.9.0->tensorflow_recommenders) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.1.2)\n",
      "Downloading tensorflow_recommenders-0.7.3-py3-none-any.whl (96 kB)\n",
      "Installing collected packages: tensorflow_recommenders\n",
      "Successfully installed tensorflow_recommenders-0.7.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45ebd5b8-638d-4489-b016-16c05baf5b07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: scann 1.4.0\n",
      "Uninstalling scann-1.4.0:\n",
      "  Successfully uninstalled scann-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall scann -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d79f56c7-b7e5-4968-a1fd-34976a079eb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q tensorflow==2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9092f642-0a9f-456b-b851-bde3b6241c06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ibis-framework 8.0.0 requires numpy<2,>=1, but you have numpy 2.2.4 which is incompatible.\n",
      "numba 0.61.0 requires numpy<2.2,>=1.24, but you have numpy 2.2.4 which is incompatible.\n",
      "pyarrow 15.0.2 requires numpy<2,>=1.16.6, but you have numpy 2.2.4 which is incompatible.\n",
      "tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 2.2.4 which is incompatible.\n",
      "ydata-profiling 4.12.2 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q numpy==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ecddf03-a5f0-4938-b24b-9ba3a869dd68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 02:06:33.971857: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-30 02:06:34.030350: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-30 02:06:34.030393: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-30 02:06:34.032333: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-30 02:06:34.043641: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-30 02:06:34.045252: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "from typing import Dict,Text\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9ca494-9fbf-4ba5-a855-f5f6d14420eb",
   "metadata": {},
   "source": [
    "Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78aa193e-856d-474d-9d20-178a5cf5a43e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Rating data\n",
    "ratings = tfds.load(\"movielens/100k-ratings\",split=\"train\")\n",
    "#Features of all candidate data\n",
    "movies = tfds.load(\"movielens/100k-movies\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9499052-2606-450d-9a95-0e05fe57b7a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 45.0,\n",
      " 'movie_genres': array([7]),\n",
      " 'movie_id': b'357',\n",
      " 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
      " 'raw_user_age': 46.0,\n",
      " 'timestamp': 879024327,\n",
      " 'user_gender': True,\n",
      " 'user_id': b'138',\n",
      " 'user_occupation_label': 4,\n",
      " 'user_occupation_text': b'doctor',\n",
      " 'user_rating': 4.0,\n",
      " 'user_zip_code': b'53211'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 02:06:44.137925: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab5ecfd9-7e6d-49c7-baf6-83454f6a2de8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': array([4]),\n",
      " 'movie_id': b'1681',\n",
      " 'movie_title': b'You So Crazy (1994)'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 02:06:46.598379: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for x in movies.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3ff0fdc-c724-4bb5-bbb1-93039674cd55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings = ratings.map(lambda x:{\n",
    "    \"movie_title\" : x[\"movie_title\"],\n",
    "    \"user_id\" : x[\"user_id\"],\n",
    "})\n",
    "\n",
    "movies = movies.map(lambda x:x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30371b2b-8e60-4a53-8a6c-4a2e20ee1fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000,seed=42,reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5491d7d9-702f-4216-8f50-31f047e9d033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie_titles = movies.batch(1_000)\n",
    "user_ids = ratings.batch(1_00_000).map(lambda x:x[\"user_id\"])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97379c7e-3213-436a-8524-d59956d5d898",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b\"'Til There Was You (1997)\", b'1-900 (1994)',\n",
       "       b'101 Dalmatians (1996)', b'12 Angry Men (1957)', b'187 (1997)',\n",
       "       b'2 Days in the Valley (1996)',\n",
       "       b'20,000 Leagues Under the Sea (1954)',\n",
       "       b'2001: A Space Odyssey (1968)',\n",
       "       b'3 Ninjas: High Noon At Mega Mountain (1998)',\n",
       "       b'39 Steps, The (1935)'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_movie_titles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4055efb7-d7a4-4dfa-aa65-3ea3b49b2ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'1', b'10', b'100', b'101', b'102', b'103', b'104', b'105',\n",
       "       b'106', b'107'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_user_ids[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5557c8c6-3d66-4497-aaf0-74c529c2d395",
   "metadata": {},
   "source": [
    "Implementing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c3c1152-e5c6-452d-885c-4052e52edc5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_dimension = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0220507-4e3d-464b-b995-ac8de2127a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_user_ids,mask_token=None),\n",
    "    tf.keras.layers.Embedding(len(unique_user_ids)+1,embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed3e28a5-a704-4c6d-a3ba-2847d3926d97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_movie_titles,mask_token=None),\n",
    "    tf.keras.layers.Embedding(len(unique_movie_titles)+1,embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0588c94b-b362-497a-8ed2-fd9ae7b486f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "    candidates = movies.batch(128).map(movie_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdb61276-34d8-40b1-bb80-d5db0ed50bef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Retrieval(metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a827af6-74ae-41d8-980e-b6f50044a8b3",
   "metadata": {},
   "source": [
    "The Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b225ab33-7cbc-4986-a3c4-9f2fad7e3893",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.Model):\n",
    "    \n",
    "    def __init__(self,user_model,movie_model):\n",
    "        super().__init__()\n",
    "        self.movie_model : tf.keras.Model = movie_model\n",
    "        self.user_model : tf.keras.Model = user_model\n",
    "        self.task : tf.keras.layers.Layer = task\n",
    "        \n",
    "    def compute_loss(self,features:Dict[Text,tf.Tensor],training=False) ->tf.Tensor:\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "        \n",
    "        return self.task(user_embeddings,movie_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cc8610-eed4-48b3-a9f8-f5e2cf9073ff",
   "metadata": {},
   "source": [
    "Fitting and Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fc9b010-4155-454b-83f2-db60ea6ff332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MovielensModel(user_model,movie_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18e10485-5a3c-42ea-8a73-660a1847c99b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cache_trained = train.shuffle(100_000).batch(8192).cache()\n",
    "cache_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c20646d5-8964-4277-9458-66bde5d78800",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 18s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0099 - factorized_top_k/top_10_categorical_accuracy: 0.0216 - factorized_top_k/top_50_categorical_accuracy: 0.1001 - factorized_top_k/top_100_categorical_accuracy: 0.1782 - loss: 69811.3146 - regularization_loss: 0.0000e+00 - total_loss: 69811.3146\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 13s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0031 - factorized_top_k/top_5_categorical_accuracy: 0.0195 - factorized_top_k/top_10_categorical_accuracy: 0.0397 - factorized_top_k/top_50_categorical_accuracy: 0.1686 - factorized_top_k/top_100_categorical_accuracy: 0.2899 - loss: 67488.4964 - regularization_loss: 0.0000e+00 - total_loss: 67488.4964\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 16s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0035 - factorized_top_k/top_5_categorical_accuracy: 0.0237 - factorized_top_k/top_10_categorical_accuracy: 0.0465 - factorized_top_k/top_50_categorical_accuracy: 0.1893 - factorized_top_k/top_100_categorical_accuracy: 0.3155 - loss: 66309.4730 - regularization_loss: 0.0000e+00 - total_loss: 66309.4730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9621516170>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cache_trained,epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af0c0468-6377-486c-88fb-d5258afabe2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 6s 515ms/step - factorized_top_k/top_1_categorical_accuracy: 7.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0091 - factorized_top_k/top_10_categorical_accuracy: 0.0209 - factorized_top_k/top_50_categorical_accuracy: 0.1211 - factorized_top_k/top_100_categorical_accuracy: 0.2360 - loss: 31076.4505 - regularization_loss: 0.0000e+00 - total_loss: 31076.4505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.000750000006519258,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.009100000374019146,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.020899999886751175,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.12110000103712082,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.23604999482631683,\n",
       " 'loss': 28237.96484375,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 28237.96484375}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cache_test,return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d669169-722c-4b99-84ce-f65c0b15ad6c",
   "metadata": {},
   "source": [
    "Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89a03b7a-fe97-4462-a657-73641cb8c75b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 42: [b'Homeward Bound: The Incredible Journey (1993)'\n",
      " b'Grumpier Old Men (1995)' b'101 Dalmatians (1996)']\n"
     ]
    }
   ],
   "source": [
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "\n",
    "index.index_from_dataset(\n",
    "    tf.data.Dataset.zip(movies.batch(100),movies.batch(100).map(model.movie_model)))\n",
    "\n",
    "_,titles = index(tf.constant([\"42\"]))\n",
    "\n",
    "print(f\"Recommendations for user 42: {titles[0,:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "310a6549-7732-4bdb-96e9-6ea7cb663077",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.22899199, -0.16064022,  0.07679612,  0.409632  , -0.26854253,\n",
       "         0.38478675, -0.26453745,  0.03933088,  0.07499922,  0.24885684,\n",
       "         0.45341435, -0.26657316,  0.46365067,  0.22015373,  0.30962116,\n",
       "         0.0554018 ,  0.05350643, -0.11967805,  0.5630117 , -0.5616781 ,\n",
       "        -0.32834166,  0.21279982, -0.01844121, -0.3354391 , -0.01276881,\n",
       "         0.20476872,  0.32642972,  0.3223742 ,  0.31260163, -0.25470287,\n",
       "         0.5752901 , -0.42915764]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ot = model.user_model.predict(tf.constant([\"42\"]))\n",
    "ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7f9351c-272b-4e7f-b4bb-fc7abc41ebc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-4.1875530e-02, -3.3552758e-03, -1.1418484e-02, -4.1328799e-02,\n",
       "         3.7990510e-05, -6.1395392e-03, -6.6739805e-03,  4.1362967e-02,\n",
       "        -8.4338896e-03, -4.3423273e-02,  3.2257233e-02,  4.4082556e-02,\n",
       "        -2.8233742e-02,  2.6133407e-02, -1.0690115e-02, -4.7576822e-02,\n",
       "        -3.4383632e-02,  1.4381114e-02,  2.5310367e-04, -2.8390264e-02,\n",
       "         4.5575093e-02, -2.3143947e-02,  2.3847070e-02, -3.9604805e-02,\n",
       "        -2.8399551e-02,  3.8856816e-02, -8.2620867e-03,  1.4367703e-02,\n",
       "         1.6659919e-02,  1.9457843e-02,  4.6380647e-03,  6.5726154e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otM = model.movie_model.predict(tf.constant([\"Harry Potter\"]))\n",
    "otM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58e7539c-0b86-4240-88ee-5cd01827d8e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# User Model\n",
    "class UserModel(tf.keras.Model):\n",
    "    def __init__(self,unique_user_ids):\n",
    "        super().__init__()\n",
    "        self.string_lookup = tf.keras.layers.StringLookup(vocabulary= unique_user_ids, mask_token=None)\n",
    "        self.embedding = tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "        self.dense = tf.keras.layers.Dense(embedding_dimension, activation=\"relu\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        user_vocab = self.string_lookup(inputs)\n",
    "        user_embedding = self.embedding(user_vocab)\n",
    "        return self.dense(user_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbebd2e4-d6b8-4c05-8756-6d2dc4000dd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Movie Model\n",
    "class MovieModel(tf.keras.Model):\n",
    "    def __init__(self,unique_movie_titles):\n",
    "        super().__init__()\n",
    "        self.string_lookup = tf.keras.layers.StringLookup(vocabulary=unique_movie_titles, mask_token=None)\n",
    "        self.embedding = tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "        self.dense = tf.keras.layers.Dense(embedding_dimension, activation=\"relu\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        movie_id = inputs  # Preserve original movie ID\n",
    "        movie_index = self.string_lookup(inputs)\n",
    "        embedding = self.embedding(movie_index)\n",
    "        embedding = self.dense(embedding)\n",
    "        return {\"movie_id\": movie_id, \"embedding\": embedding}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cb493f8-c7fd-4b04-b050-166f14ab651b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie_model2 = MovieModel(unique_movie_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4b58595-5438-42a5-9338-9cea4ed2fad6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics2 = tfrs.metrics.FactorizedTopK(\n",
    "    candidates = movies.batch(128).map(lambda x: movie_model2(x)[\"embedding\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d58ac167-1d64-40f7-9d14-5aff358cc16f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task2 = tfrs.tasks.Retrieval(metrics=metrics2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07b6a23d-e9e8-439d-bf21-d32ca33d85eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Full Two-Tower Model\n",
    "class TwoTowerModel(tfrs.models.Model):\n",
    "    def __init__(self, user_modell, movie_modell, task):\n",
    "        super().__init__()\n",
    "        self.user_model = user_modell\n",
    "        self.movie_model = movie_modell\n",
    "        self.task = task2\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        movie_output = self.movie_model(features[\"movie_title\"])\n",
    "        movie_embeddings = movie_output[\"embedding\"]\n",
    "        return self.task(user_embeddings, movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd909977-a9b3-443b-a0e2-e4193bbf7588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_model2 = UserModel(unique_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e8b5512-8b9d-4c94-b5e1-db820c3bae5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate and compile model\n",
    "model = TwoTowerModel(user_model2,movie_model2,task2)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08fb81a6-6b56-4839-ab31-e00acbc85257",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 19s 1s/step - factorized_top_k/top_1_categorical_accuracy: 3.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0026 - factorized_top_k/top_10_categorical_accuracy: 0.0054 - factorized_top_k/top_50_categorical_accuracy: 0.0298 - factorized_top_k/top_100_categorical_accuracy: 0.0609 - loss: 70367.4872 - regularization_loss: 0.0000e+00 - total_loss: 70367.4872\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 15s 2s/step - factorized_top_k/top_1_categorical_accuracy: 5.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0037 - factorized_top_k/top_10_categorical_accuracy: 0.0081 - factorized_top_k/top_50_categorical_accuracy: 0.0402 - factorized_top_k/top_100_categorical_accuracy: 0.0795 - loss: 70365.2855 - regularization_loss: 0.0000e+00 - total_loss: 70365.2855\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 13s 1s/step - factorized_top_k/top_1_categorical_accuracy: 7.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0055 - factorized_top_k/top_10_categorical_accuracy: 0.0112 - factorized_top_k/top_50_categorical_accuracy: 0.0493 - factorized_top_k/top_100_categorical_accuracy: 0.0948 - loss: 70362.1832 - regularization_loss: 0.0000e+00 - total_loss: 70362.1832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f033e74c850>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit(cache_trained, epochs=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8db9b2ee-20bb-4271-9d6c-223810488f04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save User and Movie Models for Deployment\n",
    "user_model_trained = model.user_model\n",
    "movie_model_trained = model.movie_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b49236a1-bde8-4cc2-ac59-27cb5354bb8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: user_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: user_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: movie_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: movie_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    }
   ],
   "source": [
    "# Save models separately for Vertex AI\n",
    "user_model_trained.save(\"user_model\")\n",
    "movie_model_trained.save(\"movie_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b26f63a0-e7df-4afd-8897-c9093b025fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "loaded_movie_model = tf.keras.models.load_model(\"movie_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "359c6888-d1c1-4939-8ac2-8bf2d46a946e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding': <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
      "array([[0.0315778 , 0.04169   , 0.03026812, 0.03663844, 0.        ,\n",
      "        0.        , 0.00309834, 0.        , 0.01251587, 0.        ,\n",
      "        0.08749538, 0.02146452, 0.02986801, 0.03569703, 0.04205424,\n",
      "        0.        , 0.0388275 , 0.        , 0.        , 0.01729238,\n",
      "        0.0341426 , 0.0080914 , 0.01027098, 0.00677884, 0.05901616,\n",
      "        0.        , 0.01843048, 0.04870323, 0.07441176, 0.02373037,\n",
      "        0.03263981, 0.        ]], dtype=float32)>, 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'The Woman in the back yard'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "random_movie = \"The Woman in the back yard\"\n",
    "prediction = loaded_movie_model(tf.constant([random_movie]))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "850fa733-929c-4c2e-ad42-b82e331e38a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "loaded_query_model = tf.keras.models.load_model(\"user_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "626c999d-3d20-4f30-9edb-6428b725d68e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.         0.         0.00719832 0.         0.05396531 0.\n",
      "  0.02203207 0.00657738 0.0474218  0.07067144 0.01534967 0.04755773\n",
      "  0.         0.04117741 0.04987399 0.00858011 0.00704047 0.\n",
      "  0.05137636 0.         0.00088939 0.         0.00930218 0.\n",
      "  0.01854408 0.00101339 0.         0.08081911 0.07031809 0.02777579\n",
      "  0.         0.04631174]], shape=(1, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "prediction2 = loaded_query_model(tf.constant([\"42\"]))\n",
    "print(prediction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f027b2-09c3-4341-bf03-7203d4c933ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
